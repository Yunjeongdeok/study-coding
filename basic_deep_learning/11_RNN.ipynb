{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 구글 코랩에서 실행하자.  \n",
        "## 중간에 Gensim-3.x를 사용하는데, Gensim-3.x에서 4로  업데이트 되었어다. 내가 쓰는 VSCode(로컬)은 4를 쓴다. 그래서 해당 블럭의 코드는 에러가 난다. 구글 코랩은 아직 3.x번 대를 쓰는지 실행이 잘 된다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eT8Pk_xTF75M"
      },
      "source": [
        "# 자연어 처리(Natural Language Processing, NLP)\n",
        "\n",
        "- 한국어, 영어 등 우리가 평소에 쓰는 언어\n",
        "\n",
        "- 사람의 말을 컴퓨터가 이해하도록 수행하는 과정"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XoWecPwRF8sw"
      },
      "source": [
        "## 신경망에서의 단어 처리 (단어 임베딩, Word Embedding)\n",
        "- 단어를 있는 그대로 처리하지 않고 고정 길이의 벡터로 표현 (원-핫 인코딩)\n",
        "\n",
        "- 단어 하나에 인덱스 정수를 할당하는 Bag of Words 방법\n",
        "\n",
        "- 예시)  \n",
        "  \"you\", \"are\", \"not\", \"a\", \"smart\", \"student\"\n",
        "\n",
        "  - \"you\"     : 0\n",
        "  - \"are\"     : 1\n",
        "  - \"not\"     : 2\n",
        "  - \"a\"       : 3\n",
        "  - \"smart\"   : 4\n",
        "  - \"student\" : 5\n",
        "\n",
        "        \"You are a smart student.\"  \n",
        "    ---> [1, 1, 0, 1, 1, 1]\n",
        "\n",
        "  <br>\n",
        "  \n",
        "  <img src=\"https://miro.medium.com/max/1348/1*YEJf9BQQh0ma1ECs6x_7yQ.png\" width=\"600\">\n",
        "\n",
        "  <sub>출처: https://medium.com/@athif.shaffy/one-hot-encoding-of-text-b69124bef0a7</sub>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wga06Nz-F-qI"
      },
      "source": [
        "## 신경망에서의 단어처리 구조\n",
        "\n",
        "<img src=\"https://miro.medium.com/max/1000/1*1O5gLhOg25HviI8bwZxV4g.png\" width=\"600\">\n",
        "\n",
        "<sub>출처: https://mc.ai/deep-nlp-word-vectors-with-word2vec/</sub>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g4Yk95bFTU27"
      },
      "source": [
        "## CBOW (Continuous Bag of Words) Embedding\n",
        "- 복수 단어 문맥(multi-word context)에 대한 문제  \n",
        "  즉, 여러개의 단어를 나열한 뒤 이와 관련된 단어를 추정하는 문제\n",
        "\n",
        "- 예를 들어,  \n",
        "      Betty bought a bit of better butter.\n",
        "\n",
        "  위 예시에서 (Betty, a bit, butter)라는 문맥이 주어지면 bought를 예측하는 구조\n",
        "\n",
        "  <br>\n",
        "\n",
        "  <img src=\"https://miro.medium.com/max/604/1*DfuBd49nCtT99h328iXL2Q.png\" width=\"300\">\n",
        "\n",
        "  <sub>출처: https://medium.com/@srishtee.kriti/mathematics-behind-continuous-bag-of-words-cbow-model-1e54cc2ecd88</sub>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bxa8iUpaTVsB"
      },
      "source": [
        "## Skip-Gram Embedding\n",
        "- CBOW 방식과 반대\n",
        "\n",
        "- 특정한 단어로부터 문맥이 될 수 있는 단어를 예측\n",
        "\n",
        "- 보통 입력 단어 주변의  $k$ 개 단어를 문맥으로 보고 예측 모형을 만드는데 이  $k$ 값을 window size 라고 한다.\n",
        "\n",
        "- 예시) window size = 2 라면,  \n",
        "      Betty -> bought, butter  \n",
        "      bought -> butter, Betty  \n",
        "      a -> bit, of  \n",
        "\n",
        "  <br>\n",
        "\n",
        "  <img src=\"https://www.researchgate.net/publication/322905432/figure/fig1/AS:614314310373461@1523475353979/The-architecture-of-Skip-gram-model-20.png\" width=\"300\">\n",
        "\n",
        "  <sub>출처: https://www.researchgate.net/figure/The-architecture-of-Skip-gram-model-20_fig1_322905432</sub>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZgQhTm1BTYt1"
      },
      "source": [
        "## Word2Vec\n",
        "- CBOW, Skip_Gram 방식의 단어 임베딩을 구현.  \n",
        "  구글의 Mikolov 개발\n",
        "\n",
        "- subsampling, negative sampling 등의 기법 추가하여 학습 속도 향상\n",
        "\n",
        "  <img src=\"https://mbenhaddou.com/wp-content/uploads/2019/12/img_4.png\">\n",
        "\n",
        "  <sub>출처: http://mbenhaddou.com/2019/12/14/word2vec-concepts-from-scratch/</sub>\n",
        "\n",
        "  <br>\n",
        "\n",
        "  <img src=\"https://miro.medium.com/max/2456/1*gcC7b_v7OKWutYN1NAHyMQ.png\" width=\"600\">\n",
        "\n",
        "  <sub>출처: https://towardsdatascience.com/word-embeddings-for-nlp-5b72991e01d4</sub>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "26OlAvwKTbYz"
      },
      "source": [
        "## Word2Vec 예제\n",
        "\n",
        "- 출처: https://datascienceschool.net/view-notebook/6927b0906f884a67b0da9310d3a581ee/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import nltk\n",
        "nltk.download('movie_reviews')\n",
        "nltk.download('punkt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1ABlKJAcTcw4"
      },
      "outputs": [],
      "source": [
        "from nltk.corpus import movie_reviews\n",
        "\n",
        "sentences = [list(s) for s in movie_reviews.sents()]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FrIAzCzwTc_l"
      },
      "outputs": [],
      "source": [
        "sentences[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PB7kBcQETdPv"
      },
      "outputs": [],
      "source": [
        "from gensim.models.word2vec import Word2Vec"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YO2hFz3iTda7"
      },
      "outputs": [],
      "source": [
        "model = Word2Vec(sentences)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AXJvPZZyTdV9"
      },
      "outputs": [],
      "source": [
        "model.init_sims(replace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hqQq37bITdIw"
      },
      "outputs": [],
      "source": [
        "model.wv.similarity('fruit', 'apple')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3hNQ_O18TdGs"
      },
      "outputs": [],
      "source": [
        "model.wv.similarity('he', 'she')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L95sLAsbTc4R"
      },
      "outputs": [],
      "source": [
        "model.wv.similarity('fruit', 'he')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1-U_PxqMTc20"
      },
      "outputs": [],
      "source": [
        "print('most_similarity_fruit',model.wv.most_similar('fruit'), sep='\\n')\n",
        "print()\n",
        "print('most_similarity_student',model.wv.most_similar('student'), sep='\\n')\n",
        "print()\n",
        "print('most_similarity_movie',model.wv.most_similar('movie'), sep='\\n')\n",
        "print()\n",
        "print('most_similarity_king',model.wv.most_similar('king'), sep='\\n')\n",
        "print()\n",
        "print('most_similarity_car',model.wv.most_similar('car'), sep='\\n')\n",
        "print()\n",
        "print('most_similarity_home',model.wv.most_similar('home'), sep='\\n')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hpIdkITrTwHu"
      },
      "outputs": [],
      "source": [
        "print(\"['she', 'fruit'] - apple\", model.wv.most_similar(positive=['she', 'fruit'], negative='apple', topn=2), sep='\\n')\n",
        "print()\n",
        "print(\"['she', 'king'] - queen\", model.wv.most_similar(positive=['she', 'king'], negative='queen', topn=2), sep='\\n')\n",
        "print()\n",
        "print(\"['ship', 'sky'] - sea\", model.wv.most_similar(positive=['ship', 'sky'], negative='sea', topn=2), sep='\\n')\n",
        "print()\n",
        "print(\"['ship', 'sea'] - sky\", model.wv.most_similar(positive=['ship', 'sea'], negative='sky', topn=2), sep='\\n')\n",
        "print()\n",
        "print(\"['airplane', 'sea'] - sky\", model.wv.most_similar(positive=['airplane', 'sea'], negative='sky', topn=2), sep='\\n')\n",
        "print()\n",
        "print(\"['car', 'sea'] - road\", model.wv.most_similar(positive=['car', 'sea'], negative='road', topn=2), sep='\\n')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### word2vec 간단한 구현 및 시각화"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n5PYKGZgTwSB"
      },
      "outputs": [],
      "source": [
        "from sklearn.manifold import TSNE\n",
        "\n",
        "tsne = TSNE(n_components=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# # Gensim-3.x에서 4로 바뀌었다. VSCode(로컬)은 4를 쓴다. 그래서 해당 블럭의 코드는 에러가 난다\n",
        "# # 해당 github에 들어가서 참고하면서 코드를 바꾸어보았으나 실패했다.\n",
        "# # 코랩은 아직 3.X를 쓰는지 에러가 안 난다.\n",
        "\n",
        "# review_vocab =  model.wv.vocab\n",
        "# review_similarity = model[review_vocab]\n",
        "# review_similarity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# import pandas as pd\n",
        "\n",
        "# simlilarity = tsne.fit_transform(review_similarity)\n",
        "# review_df = pd.DataFrame(simlilarity, index=review_vocab, columns=['x', 'y'])\n",
        "# review_1000 = review_df[0:1000]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# import matplotlib.pyplot as plt\n",
        "\n",
        "# fig = plt.figure(figsize=(14,14))\n",
        "# ax = fig.add_subplot(1, 1, 1)\n",
        "# ax.scatter(review_1000['x'], review_1000['y'])\n",
        "# for word, pos in review_1000.iterrows():\n",
        "#     ax.annotate(word, pos)\n",
        "# ax.axis('off')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zFyGsWqpT4tP"
      },
      "source": [
        "### 네이버 영화 감상 코퍼스를 사용한 한국어 단어 임베딩"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# # 구글 코랩을 사용할 때 할 것\n",
        "\n",
        "# import matplotlib as mpl\n",
        "# import matplotlib.pyplot as plt\n",
        "\n",
        "# %config InlineBackend.figure_format='retina'\n",
        "\n",
        "# !apt --qq -y install fonts-namum\n",
        "\n",
        "# import matplotlib.font_manager as fm\n",
        "\n",
        "# fontpath = '/usr/share/fonts/turetype/nanum/NanumBarunGothinc.ttf'\n",
        "# font = fm.FontProperties(fname=fontpath, size=9)\n",
        "# plt.rc('font', family='NanumBarunGothinc')\n",
        "# plt.rc('font', family='NanumBarunGothinc')\n",
        "# mpl.font_manager._rebuild()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- 한국어 임베딩은 \"konlpy\" 필요"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K5awuhIsTwUz"
      },
      "outputs": [],
      "source": [
        "!wget = https://raw.githubusercontent.com/e9t/nsmc/master/ratings_train.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MV16Az5MeOxr"
      },
      "outputs": [],
      "source": [
        "import codecs\n",
        "\n",
        "def read_data(filename):\n",
        "    with codecs.open(filename, encoding=\"utf-8\", mode='r') as f:\n",
        "        data = [line.split('\\t') for line in f.read().splitlines()]\n",
        "        data = data[1:]\n",
        "    return data\n",
        "\n",
        "train_data = read_data('ratings_train.txt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DbIDwP6iTwZP"
      },
      "outputs": [],
      "source": [
        "# 코랩으로 할  때 사용\n",
        "# !pip install konlpy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C60vas6reXb3"
      },
      "outputs": [],
      "source": [
        "from konlpy.tag import Okt\n",
        "tagger = Okt()\n",
        "\n",
        "def tokenize(doc):\n",
        "    return ['/'.join(t) for t in tagger.pos(doc, norm=True, stem=True)]\n",
        "\n",
        "train_docs = [row[1] for row in train_data]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aMscjdX9Tcr1"
      },
      "outputs": [],
      "source": [
        "sentences = [tokenize(d) for d in train_docs]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from gensim.models import word2vec"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = word2vec.Word2Vec(sentences)\n",
        "model.init_sims(replace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print('배우 and 여배우 유사도(similarity)', model.wv.similarity(*tokenize(u'배우 여배우')), sep='\\n')\n",
        "print()\n",
        "print('배우 and 남자 유사도', model.wv.similarity(*tokenize(u'배우 남자')), sep='\\n')\n",
        "print()\n",
        "print('한국 and 영화 유사도',model.wv.similarity(*tokenize(u'한국 영화')), sep='\\n')\n",
        "print()\n",
        "print('한국 and 프랑스 유사도',model.wv.similarity(*tokenize(u'한국 프랑스')), sep='\\n')\n",
        "print()\n",
        "print('한국 and 미국 유사도',model.wv.similarity(*tokenize(u'한국 미국')), sep='\\n')\n",
        "print()\n",
        "print('액션 and 코미디 유사도',model.wv.similarity(*tokenize(u'액션 코미디')), sep='\\n')\n",
        "print()\n",
        "print('남자 and 여자 유사도',model.wv.similarity(*tokenize(u'남자 여자')), sep='\\n')\n",
        "print()\n",
        "print('배우 and 감독 유사도',model.wv.similarity(*tokenize(u'배우 감독')), sep='\\n')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print('배우 여배우의 가장 높은 유사도(simillarity)', model.wv.most_simillarity(tokenize(u'배우 여배우')), sep='\\n')\n",
        "print()\n",
        "print('감독 가장 높은 유사도(simillarity)', model.wv.most_simillarity(tokenize(u'감독')), sep='\\n')\n",
        "print()\n",
        "print('액션 가장 높은 유사도(simillarity)', model.wv.most_simillarity(tokenize(u'액션')), sep='\\n')\n",
        "print()\n",
        "print('코미디 가장 높은 유사도(simillarity)', model.wv.most_simillarity(tokenize(u'코미디')), sep='\\n')\n",
        "print()\n",
        "print('자동차 가장 높은 유사도(simillarity)', model.wv.most_simillarity(tokenize(u'자동차')), sep='\\n')\n",
        "print()\n",
        "print('총 가장 높은 유사도(simillarity)', model.wv.most_simillarity(tokenize(u'총')), sep='\\n')\n",
        "print()\n",
        "print('무기 가장 높은 유사도(simillarity)', model.wv.most_simillarity(tokenize(u'무기')), sep='\\n')\n",
        "print()\n",
        "print('전투 가장 높은 유사도(simillarity)', model.wv.most_simillarity(tokenize(u'전투')), sep='\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from konlpy.utils import pprint\n",
        "\n",
        "pprint(model.wv.most_similar(positive=tokenize(u'남자 여배우'), negative=tokenize(u'배우'), topn=2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.manifold import TSNE\n",
        "import pandas as pd\n",
        "\n",
        "tsne = TSNE(n_components=2) \n",
        "similarity = tsne.fit_transform(review_similarity)\n",
        "review_df = pd.DataFrame(similarity, index=review_vocab, columns=['x', 'y'])\n",
        "review_1000 = review_df[:1000]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "fig = plt.figure(figsize=(14, 14))\n",
        "ax = fig.add_subplot(1, 1, 1)\n",
        "ax.scatter(review_1000['x'], review_1000['y'])\n",
        "for word, pos in review_1000.iterrows():\n",
        "    ax.annotate(word, pos)\n",
        "ax.axis('off')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jacLnynuqUXZ"
      },
      "source": [
        "# 순환 신경망 (Recurrent Neural Network, RNN)\n",
        "\n",
        "- **순서가 있는 데이터**를 입력으로 받음\n",
        "\n",
        "- 변화하는 입력에 대한 출력을 얻음\n",
        "\n",
        "- 시계열(날씨, 주가 등), 자연어와 같이 **시간의 흐름에 따라 변화하고, 그 변화가 의미를 갖는 데이터** "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3P0gpo4gqWUz"
      },
      "source": [
        "## Feed Forward Network vs Recurrent Network\n",
        "\n",
        "- Feed Forward Net (앞먹임 구조)\n",
        "  - 일반적인 구조의 신경망\n",
        "\n",
        "  - 입력 → 은닉 → 출력층 으로 이어지는 단방향 구조\n",
        "\n",
        "  - 이전 스텝의 출력의 영향을 받지 않음\n",
        "\n",
        "- Recurrent Net (되먹임 구조)\n",
        "  - 이전 층(Layer), 또는 스텝의 출력이 다시 입력으로 연결되는 신경망 구조\n",
        "\n",
        "  - 각 스텝마다 이전 상태를 기억 시스템(Memory System)  \n",
        "\n",
        "  - 현재 상태가 이전 상태에 종속\n",
        "\n",
        "  <br>\n",
        "\n",
        "  <img src=\"https://www.researchgate.net/profile/Engin_Pekel/publication/315111480/figure/fig1/AS:472548166115333@1489675670530/Feed-forward-and-recurrent-ANN-architecture.png\">\n",
        "\n",
        "  <sub>출처: https://www.researchgate.net/figure/Feed-forward-and-recurrent-ANN-architecture_fig1_315111480</sub>\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2h5HFH0BqYho"
      },
      "source": [
        "## 순환 신경망 구조\n",
        "\n",
        "<img src=\"https://colah.github.io/posts/2015-08-Understanding-LSTMs/img/RNN-unrolled.png\" width=\"700\">\n",
        "\n",
        "<br>\n",
        "\n",
        "- 입력 $x_t$에서 $t$는 시각을 뜻함\n",
        "\n",
        "- $X_0$에 대한 출력 $Y_0$이 다음 레이어에 전달\n",
        "\n",
        "- 각각의 입력에 대해 출력은 해당 레이어대로 출력값을 반환"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kowOGfSLqbSn"
      },
      "source": [
        "## 순환 신경망의 다양한 구조\n",
        "\n",
        "<img src=\"https://static.packt-cdn.com/products/9781789346640/graphics/2d4a64ef-9cf9-4b4a-9049-cb9de7a07f89.png\">\n",
        "  \n",
        "  <sub>출처: https://subscription.packtpub.com/book/big_data_and_business_intelligence/9781789346640/11/ch11lvl1sec80/introduction</sub>\n",
        "\n",
        "- one to one\n",
        "  - RNN\n",
        "\n",
        "- one to many\n",
        "  - Image Captioning \n",
        "\n",
        "  - 이미지에 대한 설명 생성\n",
        "\n",
        "- many to one\n",
        "  - Sentiment Classification\n",
        "\n",
        "  - 문장의 긍정/부정을 판단하는 감정 분석\n",
        "\n",
        "- many to many\n",
        "  - Machine Translation\n",
        "\n",
        "  - 하나의 언어를 다른 언어로 번역하는 기계 번역\n",
        "\n",
        "- many to many\n",
        "  - Video Classification(Frame Level)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uiIA4Ue7-G5B"
      },
      "source": [
        "## 두 가지 정보(현재 입력, 이전 시각의 출력)을 처리하는 수식\n",
        "$\\qquad h_t = tanh ( \\ h_{t-1} W_h \\ + \\ x_t W_x + b) $\n",
        "\n",
        "- $W_x$ : 입력 $x$를 출력 $h$로 변환하기 위한 가중치\n",
        "\n",
        "- $W_h$ : 다음 시각의 출력으로 변환하기 위한 가중치\n",
        "\n",
        "- $h$는 '상태'를 기억\n",
        "\n",
        "- $h_t \\ $를 은닉 상태(hidden state) 또는 은닉 상태 벡터(hidden state vector)라고도 불림\n",
        "\n",
        "  <sub>출처: https://colah.github.io/posts/2015-08-Understanding-LSTMs/</sub>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mNUu9LzO-KcF"
      },
      "source": [
        "## BPTT(BackPropagation Through Time)\n",
        "\n",
        "- 시간 방향으로 펼친 신경망의 오차역전파\n",
        "\n",
        "- 시계열 데이터의 시간 크기가 커지면 역전파 시 불안정해짐\n",
        "\n",
        "- 기울기 소실 문제 발생\n",
        "\n",
        "  <img src=\"https://iamtrask.github.io/img/backprop_through_time.gif\" width=\"700\">\n",
        "\n",
        "  <sub>출처: https://iamtrask.github.io/2015/11/15/anyone-can-code-lstm/</sub>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HIJmsDgw-WWS"
      },
      "source": [
        "## Truncated BPTT\n",
        "\n",
        "- 큰 시계열 데이터를 다룰 때 사용하는 오차역전파법\n",
        "\n",
        "- 신경망을 **적당한 길이로 끊는다.**\n",
        "  - <u>역전파에 연결만! 순전파의 연결은 끊어지지 않는다.</u>\n",
        "\n",
        "- 학습 시, 입력이 **순서대로 연결**되어 입력해야 함\n",
        "\n",
        "  <img src=\"https://r2rt.com/static/images/RNN_true_truncated_backprop.png\">\n",
        "\n",
        "  <sub>출처: https://r2rt.com/styles-of-truncated-backpropagation.html</sub>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9dpRw1XV-Y9n"
      },
      "source": [
        "## RNN 구현\n",
        "\n",
        "- 형상 주의!\n",
        "\n",
        "## $\\qquad \\ h_{t-1} W_h \\ + \\ x_t W_x = h_t$\n",
        "\n",
        "- $h_{t-1}$ : $N \\times H$\n",
        "\n",
        "- $W_{h}$ : $H \\times H$\n",
        "\n",
        "- $x_{t}$ : $N \\times D$\n",
        "\n",
        "- $W_{x}$ : $D \\times H$\n",
        "\n",
        "- $h_t$ : $N \\times H$\n",
        "\n",
        "- $D$ : 입력 벡터의 차원 수\n",
        "\n",
        "- $H$ : 은닉 상태 벡터의 차원 수\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Arjp1LQbuVc5"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "class RNN:\n",
        "    \n",
        "    def __init__(self, W_x, W_h, bias):\n",
        "        self.params = [W_x, W_h, bias]\n",
        "        self.grads = [np.zeros_like(W_x), np.zeros_like(W_h), np.zeros_like(bias)]\n",
        "\n",
        "        self.temp = None\n",
        "\n",
        "    def forward(self, input_data, h_prev):\n",
        "        W_x, W_h, bias = self.params\n",
        "        t = np.matmul(h_prev, W_h) + np.matmul(input_data, W_x) + bias\n",
        "        h_next = np.tanh(t)\n",
        "\n",
        "        self.temp = (input_data, h_prev, h_next)\n",
        "        return h_next\n",
        "    \n",
        "    def backward(self, dh_next):\n",
        "        W_x, W_h, bias = self.params\n",
        "        input_data, h_prev, h_next = self.temp\n",
        "\n",
        "        dt = dh_next * (1 - h_next**2)\n",
        "        db = np.sum(dt, axis=0)\n",
        "        dWh = np.matmul(h_prev.T, dt)\n",
        "        dh_prev = np.matmul(dt, W_h.T)\n",
        "        dWx = np.matmul(input_data.T, dt)\n",
        "        dx = np.matmul(dt, W_x.T)\n",
        "\n",
        "        self.grads[0][...] = dWx\n",
        "        self.grads[1][...] = dWh\n",
        "        self.grads[2][...] = db\n",
        "\n",
        "        return dx, dh_prev"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FRZ47KbtFj8O"
      },
      "source": [
        "## Time RNN Layer\n",
        "- RNN 계층의 은닉상태 $h$를 가지고 있음\n",
        " "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VQhOF1RHFhVH"
      },
      "outputs": [],
      "source": [
        "class TimeRNN:\n",
        "    \n",
        "    def __init__(self, W_x, W_h, bias, stateful=False):\n",
        "        self.params = [W_x, W_h, bias]\n",
        "        self.grads = [np.zeros_like(W_x), np.zeros_like(W_h), np.zeros_like(bias)]\n",
        "        self.layers = None\n",
        "        self.hidden_state = None\n",
        "        self.dh = None\n",
        "        self.stateful = stateful\n",
        "        \n",
        "    def set_state(self, hidden_state):\n",
        "        self.hidden_state = hidden_state\n",
        "\n",
        "    def reset_state(self):\n",
        "        self.hidden_state = None\n",
        "    \n",
        "    def forward(self, input_data):\n",
        "        W_x, W_h, bias = self.params\n",
        "        N, T, D = input_data.shape\n",
        "        D, H = W_x.shape\n",
        "        \n",
        "        self.layers = []\n",
        "        output = np.empty((N, T, H), dtype='f')\n",
        "\n",
        "        if not self.stateful or self.hidden_state is None:\n",
        "            self.hidden_state = np.zeros((N, H), dtype='f')\n",
        "        \n",
        "        for t in range(T):\n",
        "            layer = RNN(*self.params)\n",
        "            self.hidden_state = layer.forward(input_data[:, t, :], self.h)\n",
        "            output[:, t, :] = self.hidden_state\n",
        "            self.layers.append(layer)\n",
        "\n",
        "        return output\n",
        "\n",
        "    def backward(self, doutput):\n",
        "        W_x, W_h, bias = self.params\n",
        "        N, T, H = doutput.shape\n",
        "        D, H = W_x.shape\n",
        "\n",
        "        dinput = np.empty((N, T, D), dtype='f')\n",
        "        dh = 0\n",
        "        grads = [0,0,0]\n",
        "\n",
        "        for t in reversed(range(T)):\n",
        "            layer = self.layers[t]\n",
        "            dx, dh = layer.backward(doutput[:, t, :] + dh)\n",
        "            dinput[:, t, :] = dx\n",
        "\n",
        "            for i, grad in enumerate(layer.grads):\n",
        "                grads[i] += grad\n",
        "\n",
        "        for i, grad in enumerate(grads):\n",
        "            self.grads[i][...] = grad\n",
        "        \n",
        "        self.dh =dh\n",
        "\n",
        "        return dinput\n",
        "            "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KzFqvo2aFpMb"
      },
      "source": [
        "# LSTM (Long Shot-Term Memory)\n",
        "\n",
        "- RNN은 장기 기억을 제대로 처리 못함\n",
        "\n",
        "- RNN은 기울기 소실 또는 기울기 폭발을 발생\n",
        "\n",
        "- 위를 해결하기 위해 LSTM 방법 등장\n",
        "\n",
        "  <img src=\"https://www.researchgate.net/publication/324600237/figure/fig3/AS:616974623178753@1524109621725/Long-Short-term-Memory-Neural-Network.png\" width=\"600\">\n",
        "\n",
        "<sub>출처: https://www.researchgate.net/figure/Long-Short-term-Memory-Neural-Network_fig3_324600237</sub>\n",
        "\n",
        "### $\\qquad f = \\sigma (x_t W^{(f)}_x + h_{t-1} W^{(f)}_h + b^{(f)} \\\\ \n",
        "\\qquad g = tanh(x_t W^{(g)}_x + h_{t-1} W^{(g)}_h + b^{(g)}) \\\\\n",
        "\\qquad i = \\sigma(x_t W^{(i)}_x + h_{t-1} W^{(i)}_h + b^{(i)}) \\\\\n",
        "\\qquad o = tanh(x_t W^{(o)}_x + h_{t-1} W^{(o)}_h + b^{(o)})$\n",
        "\n",
        "\n",
        "### $\\qquad c_t = f \\odot c_{t-1} + g \\odot i \\\\\n",
        "\\qquad h_t = o \\odot tanh(c_t)\n",
        "$\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ii53247RFu9N"
      },
      "source": [
        "## forget gate (망각 게이트)\n",
        "- 불필요한 정보를 잊는 게이트\n",
        "\n",
        "-  $h_{t−1}$ 과 $x_t$ 를 받아 시그모이드를 취해준 값이 forget gate의 출력값\n",
        "\n",
        "- 시그모이드 함수를 통과하기 때문에 그 값이 0이라면 이전 상태의 정보는 잊고, 1이라면 이전 상태의 정보를 온전히 기억\n",
        "\n",
        "  <img src=\"https://image.slidesharecdn.com/dlsl2017d2l2recurrentneuralnetworksi-170125171004/95/recurrent-neural-networks-i-d2l2-deep-learning-for-speech-and-language-upc-2017-25-638.jpg?cb=1485365064\" width=\"600\">\n",
        "\n",
        "  <sub>출처: https://www.slideshare.net/xavigiro/recurrent-neural-networks-1-d2l2-deep-learning-for-speech-and-language-upc-2017</sub>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XXhr1CGwF1S2"
      },
      "source": [
        "## input gate (입력 게이트)\n",
        "- 현재 정보를 기억하기’ 위한 게이트\n",
        "\n",
        "- $h_{t−1}$ 과 $x_t$를 받아 $Sigmoid$ -> $tanh$ 를 통과한 다음,  \n",
        "  Hadamard product 연산을 한 값을 출력\n",
        "  \n",
        "  <br>\n",
        "\n",
        "  <img src=\"https://image.slidesharecdn.com/dlmmdcud2l08recurrentneuralnetworks-170429103823/95/recurrent-neural-networks-d2l8-insightdcu-machine-learning-workshop-2017-28-638.jpg?cb=1493462658\" width=\"600\">\n",
        "\n",
        "  <sub>출처: https://www.slideshare.net/xavigiro/recurrent-neural-networks-1-d2l2-deep-learning-for-speech-and-language-upc-2017</sub>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SyrTIpZhFxyR"
      },
      "source": [
        "## output gate (출력 게이트)\n",
        "\n",
        "- 은닉 상태 $h_t$의 출력을 담당하는 게이트\n",
        "\n",
        "- 입력 $x_t$와 이전 상태 $h_{t-1}$로부터 게이트의 열림 상태가 결정됨\n",
        "\n",
        "  <img src=\"https://image.slidesharecdn.com/dlcvd2l6recurrentneuralnetworks-160802094750/95/deep-learning-for-computer-vision-recurrent-neural-networks-upc-2016-30-638.jpg?cb=1470131837\" width=\"600\">\n",
        "\n",
        "<sub>출처: https://www.slideshare.net/xavigiro/deep-learning-for-computer-vision-recurrent-neural-networks-upc-2016</sub>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LJVkn0D6F3Yz"
      },
      "source": [
        "## LSTM 구현"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- 이수안 따라서 필사를 했다. 근데 실제로 실행은 안하고 만들기만 해서인지 몇몇은 실수로 생략을 한 것 같기도 하다.\n",
        "-  예를 들어 def backward쪽에 c가 정의되어 있지 않은 상태에서 c를 사용했다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gjrZLUk8Fpba"
      },
      "outputs": [],
      "source": [
        "def sigmoid(x):\n",
        "    return 1 / (1 + np.exp(-x))\n",
        "\n",
        "class LSTM:\n",
        "    \n",
        "    def __init__(self, W_x, W_h, bias):\n",
        "        self.params = [W_x, W_h, bias]\n",
        "        self.grads = [np.zeros_like(W_x), np.zeros_like(W_h), np.zeros_like(bias)]\n",
        "        self.temp = None\n",
        "\n",
        "    def foward(self, x, h_prev, c_prev):\n",
        "        W_x, W_h, bias = self.params\n",
        "        N, H = h_prev.shape\n",
        "\n",
        "        A = np.dot(x, W_x) + np.dot(h_prev, W_h) + bias\n",
        "\n",
        "        f = A[:, :H]\n",
        "        g = A[:, H:2*H]\n",
        "        i = A[:, 2*H:3*H]\n",
        "        o = A[:, 3*H:]\n",
        "\n",
        "        f = sigmoid(f)\n",
        "        g = np.tanh(g)\n",
        "        i = sigmoid(i)\n",
        "        o = sigmoid(o)\n",
        "        \n",
        "        c_next = f * c_prev + g * i\n",
        "        h_next = o * np.tanh(c_next)\n",
        "\n",
        "        self.temp = (x, h_prev, c_prev, i, f, g, o, c_next)\n",
        "        return h_next, c_next\n",
        "        \n",
        "    def backward(self, dh_next, dc_next):\n",
        "        W_x, W_h, bias = self.params\n",
        "        x, h_prev, c_prev, i, f, g, o, c_next = self.temp\n",
        "\n",
        "        tanh_c_next = np.tanh(c_next)\n",
        "\n",
        "        ds = dc_next + (dh_next * c) * (1 - tanh_c_next**2)\n",
        "        dc_prev = ds * f\n",
        "\n",
        "        di = ds * g\n",
        "        df = ds * c_prev\n",
        "        do = dh_next * tanh_c_next\n",
        "        dg = ds * id\n",
        "\n",
        "        di *= i * (1 - i)\n",
        "        df *= f * (1 - f)\n",
        "        do *= o * (1 - o)\n",
        "        dg *= g * (1 - g)\n",
        "\n",
        "        dA = np.hstack((df, dg, di, do))\n",
        "\n",
        "        dWh = np.dot(h_prev.T, dA)\n",
        "        dWx = np.dot(x.T, dA)\n",
        "        db = dA.sum(axis=0)\n",
        "\n",
        "        self.grads[0][...] = dWx\n",
        "        self.grads[1][...] = dWh\n",
        "        self.grads[2][...] = db\n",
        "        \n",
        "        dx = np.dot(dA, W_x.T)\n",
        "        dh_prev = np.dot(dA, W_h.T)\n",
        "\n",
        "        return dx, dh_prev, dc_prev\n",
        "        \n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dc0wuvArGHgD"
      },
      "source": [
        "# GRU (Gated Recurrent Unit)\n",
        "- LSTM을 더 단순하게 만든 구조\n",
        "\n",
        "- 기억 셀은 없고, 시간방향으로 전파하는 것은 은닉 상태만 있음\n",
        "\n",
        "- reset gate\n",
        "  - 과거의 은닉 상태를 얼마나 무시할지 결정\n",
        "\n",
        "  - $r$ 값이 결정\n",
        "\n",
        "- update gate\n",
        "  -  은닉 상태를 갱신하는 게이트  \n",
        "\n",
        "  - LSTM의 forget, input gate 역할을 동시에 함\n",
        "  \n",
        "  <img src=\"https://miro.medium.com/max/1400/1*jhi5uOm9PvZfmxvfaCektw.png\" width=\"500\">\n",
        "\n",
        "<sub>출처: https://towardsdatascience.com/illustrated-guide-to-lstms-and-gru-s-a-step-by-step-explanation-44e9eb85bf21</sub>\n",
        "\n",
        "  ### $\\qquad z = \\sigma (x_t W^{(z)}_x + h_{t-1} W^{(z)}_h + b^{(z)} \\\\ \n",
        "  \\qquad r = \\sigma (x_t W^{(r)}_x + h_{t-1} W^{(r)}_h + b^{(r)}) \\\\\n",
        "  \\qquad \\tilde{i} = tanh (x_t W^{(i)}_x + (r \\odot h_{t-1}) W^{(i)}_h + b ) \\\\\n",
        "  \\qquad h_t = (1 - z) \\odot h_{t-1} + z \\odot \\tilde{h}$\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n96GGOgsGKhE"
      },
      "source": [
        "# (참고) RNN vs LSTM vs GRU\n",
        "\n",
        "<img src=\"https://cdn.shortpixel.ai/client/q_glossy,ret_img,w_1849/http://dprogrammer.org/wp-content/uploads/2019/04/RNN-vs-LSTM-vs-GRU.png\">\n",
        "\n",
        "<sub>출처: http://dprogrammer.org/rnn-lstm-gru</sub>"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3.10.6 ('study')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    },
    "vscode": {
      "interpreter": {
        "hash": "9e5ba8102417ed24000ae30d0ee823b0df91ab90972766c536e2f5d51ee26514"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
